{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9pQdHdGrB3t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim # optimizer\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udFmJ8WM2WMN"
      },
      "source": [
        "Now we do transformation to convert an input image (or any other data) into a PyTorch tensor.\n",
        "\n",
        "Specifically, it converts pixel values (usually in the range [0, 255]) to floating-point values between 0 and 1.\n",
        "\n",
        "For example, if you have an RGB image, this transformation will convert it into a 3-channel tensor (red, green, and blue)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaarQl3stYau"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))]) # We are dealing with EMNIST, therefore only one channel is needed (mean),(std)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeHJ1B531b26",
        "outputId": "0f5c8b18-dfe4-49d5-ec8f-0a41a7122a81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip to ./data/EMNIST/raw/gzip.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 561753746/561753746 [00:12<00:00, 43710681.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/EMNIST/raw/gzip.zip to ./data/EMNIST/raw\n"
          ]
        }
      ],
      "source": [
        "train_dataset = datasets.EMNIST(root='./data',\n",
        "                                 split='balanced',  # Choose the split (e.g., 'balanced', 'letters', 'digits', etc.)\n",
        "                                 train=True,\n",
        "                                 download=True,\n",
        "                                 transform=transform) # Use defined transform\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                         batch_size=32,\n",
        "                                         shuffle = True) # Shuffle the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqL81UcaRiZ1"
      },
      "source": [
        "Separating your hyperparameters are actually a good habit!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gw5WGWrF1fXh"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "latent_dim = 100 # Latent space\n",
        "lr = 0.0002 # Learning rate, the smaller the lr, the more the time takes.\n",
        "\n",
        "# This betas are specifically for Adam optimizer\n",
        "beta1 = 0.5 # Controls the exponential decay rate for the first moment estimate (commonly set 0.9 or higher)\n",
        "beta2 = 0.999 # ... the second moment estimate\n",
        "# Higher beta (close to 1.0) means more persistant\n",
        "num_epochs = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g4cItr3amPA"
      },
      "source": [
        "Range: **Tanh** has a range of *-1 to 1*, while **ReLU** has a range of *0 to infinity*.\n",
        "\n",
        "Non-linearity: Both functions are **non-linear**, but Tanh is symmetric around the origin, while ReLU is NOT.\n",
        "\n",
        "Derivative: The derivative of Tanh is always less than 1, while the derivative of ReLU is either 0 or 1. (can refer to the picture below)\n",
        "\n",
        "Vanishing Gradient: Tanh is prone to the vanishing gradient problem, which can slow down training in deep networks. ReLU is less prone to the vanishing gradient problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_niPL_w1i7D"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128 * 28 * 28),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (128, 28, 28)),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64, momentum=0.78),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(64, 1, kernel_size=3, padding=1)  # Adjust to 1 output channel (grayscale)\n",
        "            #nn.Flatten(),  # Flatten the output to 1D tensor\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeG8_Rhu1mdq"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ZeroPad2d((0, 1, 0, 1)),\n",
        "            nn.BatchNorm2d(64, momentum=0.82),\n",
        "            nn.LeakyReLU(0.25),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128, momentum=0.82),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256, momentum=0.8),\n",
        "            nn.LeakyReLU(0.25),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Sigmoid() #sigmoid function ranged (0,1), therefore it only output yes or no by 1 and 0\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        validity = self.model(img)\n",
        "        return validity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOLLv7Kq1piU"
      },
      "outputs": [],
      "source": [
        "# Initialize generator and discriminator\n",
        "generator = Generator(latent_dim).to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "# Loss function\n",
        "adversarial_loss = nn.BCELoss()\n",
        "# ALTERNATIVELY, YOU CAN USE HINGE LOSS WHICH IS PERFECT FOR GANs (my biased opinion)\n",
        "\"\"\"\n",
        "def hinge_loss(real_logits, fake_logits):\n",
        "    D_loss = -torch.mean(torch.min(0., -1.0 + real_logits)) - torch.mean(torch.min(0., -1.0 - fake_logits))\n",
        "    G_loss = -torch.mean(fake_logits)\n",
        "    return D_loss, G_loss\n",
        "\"\"\"\n",
        "# Optimizers\n",
        "optimizer_G = optim.Adam(generator.parameters(),\n",
        "                         lr=lr,\n",
        "                         betas=(beta1, beta2))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(),\n",
        "                         lr=lr,\n",
        "                         betas=(beta1, beta2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgd732BI1qcc",
        "outputId": "e456d637-fa36-4998-ae59-57c62e8d5728"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/1] Batch 100/3525 Discriminator Loss: 0.7393 Generator Loss: 0.6100\n",
            "Epoch [1/1] Batch 200/3525 Discriminator Loss: 0.7259 Generator Loss: 0.6205\n",
            "Epoch [1/1] Batch 300/3525 Discriminator Loss: 0.7173 Generator Loss: 0.6344\n",
            "Epoch [1/1] Batch 400/3525 Discriminator Loss: 0.7106 Generator Loss: 0.6445\n",
            "Epoch [1/1] Batch 500/3525 Discriminator Loss: 0.7054 Generator Loss: 0.6541\n",
            "Epoch [1/1] Batch 600/3525 Discriminator Loss: 0.7012 Generator Loss: 0.6632\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        # Convert list to tensor\n",
        "        real_images = batch[0].to(device)\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = torch.ones((real_images.size(0), 256, 4, 4), device=device)\n",
        "        fake = torch.zeros((real_images.size(0), 256, 4, 4), device=device)\n",
        "        # Configure input\n",
        "        real_images = real_images.to(device)\n",
        "\n",
        "        # ---------------------\n",
        "        # Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad() #Set zero gradient\n",
        "\n",
        "        # Sample noise as generator input\n",
        "        z = torch.randn(real_images.size(0), latent_dim, device=device)\n",
        "\n",
        "        # Generate a batch of images\n",
        "        fake_images = generator(z)\n",
        "        fake_images_resized = F.interpolate(fake_images, size=(28, 28), mode='bilinear', align_corners=False)\n",
        "\n",
        "        # Measure discriminator's ability\n",
        "        # to classify real and fake images\n",
        "        real_loss = adversarial_loss(discriminator(real_images), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(fake_images_resized.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # -----------------\n",
        "        # Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Generate a batch of images\n",
        "        gen_images = generator(z)\n",
        "        gen_images_resized = F.interpolate(gen_images, size=(28, 28), mode='bilinear', align_corners=False)\n",
        "\n",
        "        # Adversarial loss\n",
        "        g_loss = adversarial_loss(discriminator(gen_images_resized), valid)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        # Progress Monitoring\n",
        "        # ---------------------\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
        "                f\"Batch {i+1}/{len(dataloader)} \"\n",
        "                f\"Discriminator Loss: {d_loss.item():.4f} \"\n",
        "                f\"Generator Loss: {g_loss.item():.4f}\"\n",
        "            )\n",
        "\n",
        "    # Save generated images for every epoch\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        with torch.no_grad():\n",
        "            z = torch.randn(16, latent_dim, device=device)\n",
        "            generated = generator(z).detach().cpu()\n",
        "            grid = torchvision.utils.make_grid(generated, nrow=4, normalize=True)\n",
        "            plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0_ZVAFAgBR8"
      },
      "source": [
        "## References\n",
        "https://towardsdatascience.com/generative-adversarial-networks-gans-a-beginners-guide-f37c9f3b7817\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
